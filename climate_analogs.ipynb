{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13244aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512c3f01",
   "metadata": {},
   "source": [
    "## Load and prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba795b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(df):\n",
    "    \"\"\"Extract metadata columns (city, latitude, longitude) from the dataframe.\"\"\"\n",
    "    return df[['city', 'latitude', 'longitude']]\n",
    "\n",
    "def get_climate_features(df):\n",
    "    \"\"\"Extract climate feature columns by dropping metadata columns.\"\"\"\n",
    "    return df.drop(columns=['city', 'latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a53dffa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded climate_features_1970-1979.csv with shape (292, 27)\n",
      "Loaded climate_features_1980-1989.csv with shape (292, 27)\n",
      "Loaded climate_features_1990-1999.csv with shape (292, 27)\n",
      "Loaded climate_features_2000-2009.csv with shape (292, 27)\n",
      "Loaded climate_features_2010-2020.csv with shape (292, 27)\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets from CSV files\n",
    "\n",
    "period_names = ['1970-1979', '1980-1989', '1990-1999', '2000-2009', '2010-2020']\n",
    "datasets = {}\n",
    "\n",
    "for period_name in period_names:\n",
    "    datasets[period_name] = pd.read_csv(f\"datasets/climate_features_{period_name}.csv\")\n",
    "    print(f\"Loaded climate_features_{period_name}.csv with shape {datasets[period_name].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a31edf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only climate features for analysis\n",
    "\n",
    "climate_ds = {}\n",
    "\n",
    "for period_name in period_names:\n",
    "    climate_ds[period_name] = get_climate_features(datasets[period_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9b97cc",
   "metadata": {},
   "source": [
    "## Load PCA and scaler models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8860ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = joblib.load('models/pca_historical.joblib')\n",
    "scaler = joblib.load('models/scaler_pca_historical.joblib')\n",
    "feature_columns = joblib.load('models/feature_columns.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47bba94",
   "metadata": {},
   "source": [
    "## Apply PCA and scaler to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3ad1e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nb_min_components_for_variance(pca, target_explained_variance=0.9):\n",
    "    \"\"\"Find the minimum number of PCA components needed to explain the target variance.\n",
    "        Arguments:\n",
    "            pca: Trained PCA object\n",
    "            target_explained_variance: Target explained variance (default is 0.9)\n",
    "        Returns: Minimum number of components needed to explain the target variance\n",
    "    \"\"\"\n",
    "    cummulated_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "    min_index = np.sum(cummulated_variance < target_explained_variance)\n",
    "\n",
    "    return min_index + 1\n",
    "\n",
    "def project_data_pca(df, scaler, pca, n_components):\n",
    "    \n",
    "    \"\"\"Project data using scaler and PCA with specified number of components.\n",
    "        Arguments:\n",
    "            df: Input dataframe to project\n",
    "            scaler: Trained StandardScaler object\n",
    "            pca: Trained PCA object\n",
    "            n_components: Number of PCA components to use for projection\n",
    "        Returns: Function that projects input data using the scaler and PCA\n",
    "    \"\"\"\n",
    "\n",
    "    scaled_data = scaler.transform(df)\n",
    "    projected_data = pca.transform(scaled_data)[:, :n_components]\n",
    "\n",
    "    return projected_data\n",
    "\n",
    "def add_metadata_to_df(df, metadata):\n",
    "    return pd.concat([metadata, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c16a73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of PCA components to explain 90.0% variance: 3\n"
     ]
    }
   ],
   "source": [
    "TARGET_EXPLAINED_VARIANCE = 0.9\n",
    "\n",
    "min_components = find_nb_min_components_for_variance(pca, TARGET_EXPLAINED_VARIANCE)\n",
    "print(f\"Minimum number of PCA components to explain {TARGET_EXPLAINED_VARIANCE*100}% variance: {min_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c4e78cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA DataFrame for 1970-1979 shape: (292, 6)\n",
      "PCA DataFrame for 1980-1989 shape: (292, 6)\n",
      "PCA DataFrame for 1990-1999 shape: (292, 6)\n",
      "PCA DataFrame for 2000-2009 shape: (292, 6)\n",
      "PCA DataFrame for 2010-2020 shape: (292, 6)\n"
     ]
    }
   ],
   "source": [
    "pca_df = {}\n",
    "\n",
    "for period_name in period_names:\n",
    "    projected_data = project_data_pca(climate_ds[period_name][feature_columns], scaler, pca, min_components)\n",
    "    pca_df[period_name] = pd.DataFrame(projected_data, columns=[f'PC{i+1}' for i in range(min_components)])\n",
    "    metadata = get_metadata(datasets[period_name])\n",
    "    pca_df[period_name] = add_metadata_to_df(pca_df[period_name], metadata)\n",
    "    print(f\"PCA DataFrame for {period_name} shape: {pca_df[period_name].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c005d6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachen</td>\n",
       "      <td>50.776642</td>\n",
       "      <td>6.08342</td>\n",
       "      <td>-0.126268</td>\n",
       "      <td>0.146205</td>\n",
       "      <td>0.496767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>57.143688</td>\n",
       "      <td>-2.09814</td>\n",
       "      <td>-0.639263</td>\n",
       "      <td>-0.533712</td>\n",
       "      <td>1.603871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aix-en-Provence</td>\n",
       "      <td>43.528301</td>\n",
       "      <td>5.44973</td>\n",
       "      <td>-2.208006</td>\n",
       "      <td>0.396590</td>\n",
       "      <td>-0.366904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alcalá de Henares</td>\n",
       "      <td>40.482052</td>\n",
       "      <td>-3.35996</td>\n",
       "      <td>-2.097754</td>\n",
       "      <td>0.117210</td>\n",
       "      <td>-1.199937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alicante</td>\n",
       "      <td>38.345169</td>\n",
       "      <td>-0.48149</td>\n",
       "      <td>-3.306525</td>\n",
       "      <td>0.221981</td>\n",
       "      <td>-1.022172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                city   latitude  longitude       PC1       PC2       PC3\n",
       "0             Aachen  50.776642    6.08342 -0.126268  0.146205  0.496767\n",
       "1           Aberdeen  57.143688   -2.09814 -0.639263 -0.533712  1.603871\n",
       "2    Aix-en-Provence  43.528301    5.44973 -2.208006  0.396590 -0.366904\n",
       "3  Alcalá de Henares  40.482052   -3.35996 -2.097754  0.117210 -1.199937\n",
       "4           Alicante  38.345169   -0.48149 -3.306525  0.221981 -1.022172"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pca_df['2010-2020'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8e120",
   "metadata": {},
   "source": [
    "## Find closest city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10b7e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial.distance import mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ae2bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distance_matrix(ds_current, ds_target, distance_metric='euclidean'):\n",
    "    \n",
    "    distances = [[0 for _ in range(ds_target.shape[0])] for _ in range(ds_current.shape[0])]\n",
    "\n",
    "    for i in range(ds_current.shape[0]):\n",
    "        for j in range(ds_target.shape[0]):\n",
    "            if distance_metric == 'euclidean':\n",
    "                distances[i][j] = euclidean_distances([ds_current.iloc[i, 3:]], [ds_target.iloc[j, 3:]])[0][0]\n",
    "            elif distance_metric == 'mahalanobis':\n",
    "                VI = np.linalg.inv(np.cov(ds_target.iloc[:, 3:].T))\n",
    "                distances[i][j] = mahalanobis(ds_current.iloc[i, 3:], ds_target.iloc[j, 3:], VI)           \n",
    "            else:\n",
    "                raise ValueError(\"Unsupported distance metric. Use 'euclidean' or 'mahalanobis'.\")\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "293203ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_city(\n",
    "    target_ds,\n",
    "    current_ds,\n",
    "    current_city,\n",
    "    distance_matrix\n",
    "):\n",
    "    \"\"\"\n",
    "    Distances above the percentile defined by `threshold`\n",
    "    (computed on all elements of the distance matrix)\n",
    "    are considered too far.\n",
    "    \"\"\"\n",
    "\n",
    "    distance_matrix = np.asarray(distance_matrix)\n",
    "\n",
    "    # Find index of the city in current_ds by name\n",
    "    mask = current_ds['city'] == current_city\n",
    "\n",
    "    if not mask.any():\n",
    "        raise ValueError(\n",
    "            f\"City at coordinates {current_city} not found in the current dataset.\"\n",
    "        )\n",
    "\n",
    "    current_index = current_ds[mask].index[0]\n",
    "\n",
    "    # Closest city\n",
    "    distances = distance_matrix[current_index]\n",
    "    closest_index = np.argmin(distances)\n",
    "    closest_distance = distances[closest_index]\n",
    "\n",
    "    closest_city = target_ds.iloc[closest_index]['city']\n",
    "    return closest_city, closest_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4cefc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bern = (46.916666666666664, 7.466667)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2c0cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_distances_matrix = create_distance_matrix(pca_df['1970-1979'], pca_df['2010-2020'], distance_metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a4349b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Bern', np.float64(0.7597246664849151))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest_city(pca_df['2010-2020'], pca_df['1970-1979'], 'Bern', euclidean_distances_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "001c3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = get_metadata(datasets['2010-2020'])\n",
    "names = datasets['2010-2020'][['city']]\n",
    "cities = pd.DataFrame(columns=['city_1970', 'city_analog_today'])\n",
    "\n",
    "distances = []\n",
    "\n",
    "# For each city: find which city has TODAY (2020) the climate that this city WILL HAVE (2050)\n",
    "for city, lat, long in metadata.values:\n",
    "    # Find the city's future climate (2050) and match it with current climates (2020)\n",
    "    closest_city = find_closest_city(\n",
    "        pca_df['2010-2020'],   # target: search in current climates (2020)\n",
    "        pca_df['1970-1979'],   # current: the city's future climate (2050)\n",
    "        city, \n",
    "        euclidean_distances_matrix\n",
    "    )\n",
    "    new_row = pd.DataFrame([[city, closest_city[0]]], \n",
    "                          columns=['city_1970', 'city_analog_today'])\n",
    "    cities = pd.concat([cities, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92eb51eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_1970</th>\n",
       "      <th>city_analog_today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachen</td>\n",
       "      <td>Aachen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>Aberdeen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aix-en-Provence</td>\n",
       "      <td>Montpellier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alcalá de Henares</td>\n",
       "      <td>Krasnodar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alicante</td>\n",
       "      <td>Valencia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Zagreb</td>\n",
       "      <td>Zagreb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Zaragoza</td>\n",
       "      <td>Salamanca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Zürich</td>\n",
       "      <td>Bern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Århus</td>\n",
       "      <td>Gdynia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Łódź</td>\n",
       "      <td>Vilnius</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             city_1970 city_analog_today\n",
       "0               Aachen            Aachen\n",
       "1             Aberdeen          Aberdeen\n",
       "2      Aix-en-Provence       Montpellier\n",
       "3    Alcalá de Henares         Krasnodar\n",
       "4             Alicante          Valencia\n",
       "..                 ...               ...\n",
       "287             Zagreb            Zagreb\n",
       "288           Zaragoza         Salamanca\n",
       "289             Zürich              Bern\n",
       "290              Århus            Gdynia\n",
       "291               Łódź           Vilnius\n",
       "\n",
       "[292 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8d6dd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Percentage of cities that remained the same: 13.70%'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of cities that remained the same\n",
    "same_city_count = np.sum(cities['city_1970'] == cities['city_analog_today'])\n",
    "total_cities = len(cities)\n",
    "\n",
    "f\"Percentage of cities that remained the same: {same_city_count / total_cities * 100:.2f}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5477947",
   "metadata": {},
   "source": [
    "## Save distances matrices in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "345fdfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_csv(matrix, filename):\n",
    "    \"\"\"Save distance matrix to CSV with columns starting at 1.\"\"\"\n",
    "    df = pd.DataFrame(matrix)\n",
    "    df.columns = [str(i+1) for i in range(len(df.columns))]\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84839edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_to_csv(euclidean_distances_matrix, 'distances/euclidean_1970-1979_ssp580.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlbd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
