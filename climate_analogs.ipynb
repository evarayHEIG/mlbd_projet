{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13244aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512c3f01",
   "metadata": {},
   "source": [
    "## Load and prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba795b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(df):\n",
    "    \"\"\"Extract metadata columns (city, latitude, longitude) from the dataframe.\"\"\"\n",
    "    return df[['city', 'latitude', 'longitude']]\n",
    "\n",
    "def get_climate_features(df):\n",
    "    \"\"\"Extract climate feature columns by dropping metadata columns.\"\"\"\n",
    "    return df.drop(columns=['city', 'latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a53dffa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded climate_features_1970-1979.csv with shape (292, 27)\n",
      "Loaded climate_features_2010-2020.csv with shape (292, 27)\n",
      "Loaded climate_features_2041-2050_future_ssp585.csv with shape (292, 27)\n",
      "Loaded climate_features_2041-2050_future_ssp370.csv with shape (292, 27)\n",
      "Loaded climate_features_2041-2050_future_ssp126.csv with shape (292, 27)\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets from CSV files\n",
    "\n",
    "period_names = ['1970-1979', '2010-2020', '2041-2050_future_ssp585', '2041-2050_future_ssp370', '2041-2050_future_ssp126']\n",
    "datasets = {}\n",
    "\n",
    "for period_name in period_names:\n",
    "    datasets[period_name] = pd.read_csv(f\"datasets/climate_features_{period_name}.csv\")\n",
    "    print(f\"Loaded climate_features_{period_name}.csv with shape {datasets[period_name].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a31edf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only climate features for analysis\n",
    "\n",
    "climate_ds = {}\n",
    "\n",
    "for period_name in period_names:\n",
    "    climate_ds[period_name] = get_climate_features(datasets[period_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9b97cc",
   "metadata": {},
   "source": [
    "## Load PCA and scaler models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8860ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = joblib.load('models/pca_historical.joblib')\n",
    "scaler = joblib.load('models/scaler_pca_historical.joblib')\n",
    "feature_columns = joblib.load('models/feature_columns.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47bba94",
   "metadata": {},
   "source": [
    "## Apply PCA and scaler to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3ad1e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nb_min_components_for_variance(pca, target_explained_variance=0.9):\n",
    "    \"\"\"Find the minimum number of PCA components needed to explain the target variance.\n",
    "        Arguments:\n",
    "            pca: Trained PCA object\n",
    "            target_explained_variance: Target explained variance (default is 0.9)\n",
    "        Returns: Minimum number of components needed to explain the target variance\n",
    "    \"\"\"\n",
    "    cummulated_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "    min_index = np.sum(cummulated_variance < target_explained_variance)\n",
    "\n",
    "    return min_index + 1\n",
    "\n",
    "def project_data_pca(df, scaler, pca, n_components):\n",
    "    \n",
    "    \"\"\"Project data using scaler and PCA with specified number of components.\n",
    "        Arguments:\n",
    "            df: Input dataframe to project\n",
    "            scaler: Trained StandardScaler object\n",
    "            pca: Trained PCA object\n",
    "            n_components: Number of PCA components to use for projection\n",
    "        Returns: Function that projects input data using the scaler and PCA\n",
    "    \"\"\"\n",
    "\n",
    "    scaled_data = scaler.transform(df)\n",
    "    projected_data = pca.transform(scaled_data)[:, :n_components]\n",
    "\n",
    "    return projected_data\n",
    "\n",
    "def add_metadata_to_df(df, metadata):\n",
    "    return pd.concat([metadata, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c16a73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of PCA components to explain 90.0% variance: 4\n"
     ]
    }
   ],
   "source": [
    "TARGET_EXPLAINED_VARIANCE = 0.9\n",
    "\n",
    "min_components = find_nb_min_components_for_variance(pca, TARGET_EXPLAINED_VARIANCE)\n",
    "print(f\"Minimum number of PCA components to explain {TARGET_EXPLAINED_VARIANCE*100}% variance: {min_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c4e78cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA DataFrame for 1970-1979 shape: (292, 7)\n",
      "PCA DataFrame for 2010-2020 shape: (292, 7)\n",
      "PCA DataFrame for 2041-2050_future_ssp585 shape: (292, 7)\n",
      "PCA DataFrame for 2041-2050_future_ssp370 shape: (292, 7)\n",
      "PCA DataFrame for 2041-2050_future_ssp126 shape: (292, 7)\n"
     ]
    }
   ],
   "source": [
    "pca_df = {}\n",
    "\n",
    "for period_name in period_names:\n",
    "    projected_data = project_data_pca(climate_ds[period_name][feature_columns], scaler, pca, min_components)\n",
    "    pca_df[period_name] = pd.DataFrame(projected_data, columns=[f'PC{i+1}' for i in range(min_components)])\n",
    "    metadata = get_metadata(datasets[period_name])\n",
    "    pca_df[period_name] = add_metadata_to_df(pca_df[period_name], metadata)\n",
    "    print(f\"PCA DataFrame for {period_name} shape: {pca_df[period_name].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c005d6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachen</td>\n",
       "      <td>50.776642</td>\n",
       "      <td>6.08342</td>\n",
       "      <td>-0.071734</td>\n",
       "      <td>0.130183</td>\n",
       "      <td>0.616279</td>\n",
       "      <td>-0.310959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>57.143688</td>\n",
       "      <td>-2.09814</td>\n",
       "      <td>-1.083642</td>\n",
       "      <td>0.243241</td>\n",
       "      <td>2.213594</td>\n",
       "      <td>0.215005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aix-en-Provence</td>\n",
       "      <td>43.528301</td>\n",
       "      <td>5.44973</td>\n",
       "      <td>-1.972830</td>\n",
       "      <td>0.050951</td>\n",
       "      <td>-0.400779</td>\n",
       "      <td>0.555935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alcalá de Henares</td>\n",
       "      <td>40.482052</td>\n",
       "      <td>-3.35996</td>\n",
       "      <td>-1.807056</td>\n",
       "      <td>-0.593693</td>\n",
       "      <td>-1.693132</td>\n",
       "      <td>0.629092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alicante</td>\n",
       "      <td>38.345169</td>\n",
       "      <td>-0.48149</td>\n",
       "      <td>-2.961560</td>\n",
       "      <td>-0.450912</td>\n",
       "      <td>-1.191013</td>\n",
       "      <td>1.166077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                city   latitude  longitude       PC1       PC2       PC3  \\\n",
       "0             Aachen  50.776642    6.08342 -0.071734  0.130183  0.616279   \n",
       "1           Aberdeen  57.143688   -2.09814 -1.083642  0.243241  2.213594   \n",
       "2    Aix-en-Provence  43.528301    5.44973 -1.972830  0.050951 -0.400779   \n",
       "3  Alcalá de Henares  40.482052   -3.35996 -1.807056 -0.593693 -1.693132   \n",
       "4           Alicante  38.345169   -0.48149 -2.961560 -0.450912 -1.191013   \n",
       "\n",
       "        PC4  \n",
       "0 -0.310959  \n",
       "1  0.215005  \n",
       "2  0.555935  \n",
       "3  0.629092  \n",
       "4  1.166077  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pca_df['2010-2020'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3568e8ca",
   "metadata": {},
   "source": [
    "## Load encoder embeddings\n",
    "\n",
    "Load the embeddings generated by the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bd5846c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical embeddings loaded:\n",
      "  1970-1979: shape (292, 6)\n",
      "  1980-1989: shape (292, 6)\n",
      "  1990-1999: shape (292, 6)\n",
      "  2000-2009: shape (292, 6)\n",
      "  2010-2020: shape (292, 6)\n",
      "\n",
      "Future embeddings loaded:\n",
      "  2041-2050_ssp126: shape (292, 6)\n",
      "  2041-2050_ssp370: shape (292, 6)\n",
      "  2041-2050_ssp585: shape (292, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the saved encoder embeddings\n",
    "encoder_historical_embeddings = joblib.load('models/encoder_historical_embeddings.joblib')\n",
    "encoder_future_embeddings = joblib.load('models/encoder_future_embeddings.joblib')\n",
    "\n",
    "print(\"Historical embeddings loaded:\")\n",
    "for key in encoder_historical_embeddings.keys():\n",
    "    print(f\"  {key}: shape {encoder_historical_embeddings[key].shape}\")\n",
    "\n",
    "print(\"\\nFuture embeddings loaded:\")\n",
    "for key in encoder_future_embeddings.keys():\n",
    "    print(f\"  {key}: shape {encoder_future_embeddings[key].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8e120",
   "metadata": {},
   "source": [
    "## Find closest city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10b7e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial.distance import mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ae2bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distance_matrix(ds_current, ds_target, distance_metric='euclidean'):\n",
    "    \n",
    "    distances = [[0 for _ in range(ds_target.shape[0])] for _ in range(ds_current.shape[0])]\n",
    "\n",
    "    for i in range(ds_current.shape[0]):\n",
    "        for j in range(ds_target.shape[0]):\n",
    "            if distance_metric == 'euclidean':\n",
    "                distances[i][j] = euclidean_distances([ds_current.iloc[i, 3:]], [ds_target.iloc[j, 3:]])[0][0]\n",
    "            elif distance_metric == 'mahalanobis':\n",
    "                VI = np.linalg.inv(np.cov(ds_target.iloc[:, 3:].T))\n",
    "                distances[i][j] = mahalanobis(ds_current.iloc[i, 3:], ds_target.iloc[j, 3:], VI)           \n",
    "            else:\n",
    "                raise ValueError(\"Unsupported distance metric. Use 'euclidean' or 'mahalanobis'.\")\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "293203ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_city(\n",
    "    target_ds,\n",
    "    current_ds,\n",
    "    current_city,\n",
    "    distance_matrix\n",
    "):\n",
    "    \"\"\"\n",
    "    Distances above the percentile defined by `threshold`\n",
    "    (computed on all elements of the distance matrix)\n",
    "    are considered too far.\n",
    "    \"\"\"\n",
    "\n",
    "    distance_matrix = np.asarray(distance_matrix)\n",
    "\n",
    "    # Find index of the city in current_ds by name\n",
    "    mask = current_ds['city'] == current_city\n",
    "\n",
    "    if not mask.any():\n",
    "        raise ValueError(\n",
    "            f\"City at coordinates {current_city} not found in the current dataset.\"\n",
    "        )\n",
    "\n",
    "    current_index = current_ds[mask].index[0]\n",
    "\n",
    "    # Closest city\n",
    "    distances = distance_matrix[current_index]\n",
    "    closest_index = np.argmin(distances)\n",
    "    closest_distance = distances[closest_index]\n",
    "\n",
    "    closest_city = target_ds.iloc[closest_index]['city']\n",
    "    return closest_city, closest_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2c0cee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing euclidean distance matrix for period 1970-1979...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Computing mahalanobis distance matrix for period 1970-1979...\n",
      "Done\n",
      "Computing euclidean distance matrix for period 2041-2050_future_ssp585...\n",
      "Done\n",
      "Computing euclidean distance matrix for period 2041-2050_future_ssp585...\n",
      "Done\n",
      "Computing mahalanobis distance matrix for period 2041-2050_future_ssp585...\n",
      "Done\n",
      "Computing mahalanobis distance matrix for period 2041-2050_future_ssp585...\n",
      "Done\n",
      "Computing euclidean distance matrix for period 2041-2050_future_ssp370...\n",
      "Done\n",
      "Computing euclidean distance matrix for period 2041-2050_future_ssp370...\n",
      "Done\n",
      "Computing mahalanobis distance matrix for period 2041-2050_future_ssp370...\n",
      "Done\n",
      "Computing mahalanobis distance matrix for period 2041-2050_future_ssp370...\n",
      "Done\n",
      "Computing euclidean distance matrix for period 2041-2050_future_ssp126...\n",
      "Done\n",
      "Computing euclidean distance matrix for period 2041-2050_future_ssp126...\n",
      "Done\n",
      "Computing mahalanobis distance matrix for period 2041-2050_future_ssp126...\n",
      "Done\n",
      "Computing mahalanobis distance matrix for period 2041-2050_future_ssp126...\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "distance_kinds = ['euclidean', 'mahalanobis']\n",
    "present = pca_df['2010-2020']\n",
    "distance_matrices = {}\n",
    "\n",
    "for period in period_names:\n",
    "    if period == '2010-2020':\n",
    "        continue # skip present period\n",
    "    for distance_kind in distance_kinds:\n",
    "        print(f\"Computing {distance_kind} distance matrix for period {period}...\")\n",
    "        distance_matrices[f'{distance_kind}_{period}'] = create_distance_matrix(pca_df[period], present, distance_metric=distance_kind)\n",
    "        print('Done')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "001c3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_distances_matrix = distance_matrices['euclidean_1970-1979']\n",
    "\n",
    "metadata = get_metadata(datasets['2010-2020'])\n",
    "names = datasets['2010-2020'][['city']]\n",
    "cities = pd.DataFrame(columns=['city_1970', 'city_analog_today'])\n",
    "\n",
    "distances = []\n",
    "\n",
    "# For each city: find which city has TODAY (2020) the climate that this city WILL HAVE (2050)\n",
    "for city, lat, long in metadata.values:\n",
    "    # Find the city's future climate (2050) and match it with current climates (2020)\n",
    "    closest_city = find_closest_city(\n",
    "        pca_df['2010-2020'],   # target: search in current climates (2020)\n",
    "        pca_df['1970-1979'],   # current: the city's future climate (2050)\n",
    "        city, \n",
    "        euclidean_distances_matrix\n",
    "    )\n",
    "    new_row = pd.DataFrame([[city, closest_city[0]]], \n",
    "                          columns=['city_1970', 'city_analog_today'])\n",
    "    cities = pd.concat([cities, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92eb51eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_1970</th>\n",
       "      <th>city_analog_today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachen</td>\n",
       "      <td>Aachen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>Aberdeen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aix-en-Provence</td>\n",
       "      <td>Montpellier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alcalá de Henares</td>\n",
       "      <td>Alcalá de Henares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alicante</td>\n",
       "      <td>Valencia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Zagreb</td>\n",
       "      <td>Zagreb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Zaragoza</td>\n",
       "      <td>Valladolid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Zürich</td>\n",
       "      <td>Bern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Århus</td>\n",
       "      <td>Gdynia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Łódź</td>\n",
       "      <td>Vilnius</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             city_1970  city_analog_today\n",
       "0               Aachen             Aachen\n",
       "1             Aberdeen           Aberdeen\n",
       "2      Aix-en-Provence        Montpellier\n",
       "3    Alcalá de Henares  Alcalá de Henares\n",
       "4             Alicante           Valencia\n",
       "..                 ...                ...\n",
       "287             Zagreb             Zagreb\n",
       "288           Zaragoza         Valladolid\n",
       "289             Zürich               Bern\n",
       "290              Århus             Gdynia\n",
       "291               Łódź            Vilnius\n",
       "\n",
       "[292 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8d6dd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Percentage of cities that remained the same: 25.68%'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of cities that remained the same\n",
    "same_city_count = np.sum(cities['city_1970'] == cities['city_analog_today'])\n",
    "total_cities = len(cities)\n",
    "\n",
    "f\"Percentage of cities that remained the same: {same_city_count / total_cities * 100:.2f}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5477947",
   "metadata": {},
   "source": [
    "## Save distances matrices in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "345fdfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_csv(matrix, filename):\n",
    "    \"\"\"Save distance matrix to CSV with columns starting at 1.\"\"\"\n",
    "    df = pd.DataFrame(matrix)\n",
    "    df.columns = [str(i+1) for i in range(len(df.columns))]\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84839edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, matrix in distance_matrices.items():\n",
    "    matrix_to_csv(matrix, f'distance_matrices/pca_{key}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f150e9a",
   "metadata": {},
   "source": [
    "## Compute and save distance matrices for encoder embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caa1e23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing euclidean distance matrix for encoder embeddings 1970-1979...\n",
      "Done\n",
      "Computing mahalanobis distance matrix for encoder embeddings 1970-1979...\n",
      "Done\n",
      "Computing mahalanobis distance matrix for encoder embeddings 1970-1979...\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Compute distance matrices for historical period (1970-1979)\n",
    "encoder_distance_matrices = {}\n",
    "distance_kinds = ['euclidean', 'mahalanobis']\n",
    "\n",
    "# Use 2010-2020 as the reference period\n",
    "reference_period = '2010-2020'\n",
    "encoder_reference = encoder_historical_embeddings[reference_period]\n",
    "\n",
    "# Compute for historical period 1970-1979\n",
    "historical_period = '1970-1979'\n",
    "for distance_kind in distance_kinds:\n",
    "    print(f\"Computing {distance_kind} distance matrix for encoder embeddings {historical_period}...\")\n",
    "    encoder_distance_matrices[f'{distance_kind}_{historical_period}'] = create_distance_matrix(\n",
    "        encoder_historical_embeddings[historical_period], \n",
    "        encoder_reference, \n",
    "        distance_metric=distance_kind\n",
    "    )\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5891231b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing euclidean distance matrix for encoder embeddings 2041-2050_ssp126...\n",
      "Done\n",
      "Computing mahalanobis distance matrix for encoder embeddings 2041-2050_ssp126...\n",
      "Done\n",
      "Computing mahalanobis distance matrix for encoder embeddings 2041-2050_ssp126...\n",
      "Done\n",
      "Computing euclidean distance matrix for encoder embeddings 2041-2050_ssp370...\n",
      "Done\n",
      "Computing euclidean distance matrix for encoder embeddings 2041-2050_ssp370...\n",
      "Done\n",
      "Computing mahalanobis distance matrix for encoder embeddings 2041-2050_ssp370...\n",
      "Done\n",
      "Computing mahalanobis distance matrix for encoder embeddings 2041-2050_ssp370...\n",
      "Done\n",
      "Computing euclidean distance matrix for encoder embeddings 2041-2050_ssp585...\n",
      "Done\n",
      "Computing euclidean distance matrix for encoder embeddings 2041-2050_ssp585...\n",
      "Done\n",
      "Computing mahalanobis distance matrix for encoder embeddings 2041-2050_ssp585...\n",
      "Done\n",
      "Computing mahalanobis distance matrix for encoder embeddings 2041-2050_ssp585...\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Compute for future scenarios (2041-2050 with ssp126, ssp370, ssp585)\n",
    "for key in encoder_future_embeddings.keys():\n",
    "    for distance_kind in distance_kinds:\n",
    "        print(f\"Computing {distance_kind} distance matrix for encoder embeddings {key}...\")\n",
    "        encoder_distance_matrices[f'{distance_kind}_{key}'] = create_distance_matrix(\n",
    "            encoder_future_embeddings[key], \n",
    "            encoder_reference, \n",
    "            distance_metric=distance_kind\n",
    "        )\n",
    "        print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38f9adf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved distance_matrices/embedding_euclidean_1970-1979.csv\n",
      "Saved distance_matrices/embedding_mahalanobis_1970-1979.csv\n",
      "Saved distance_matrices/embedding_euclidean_2041-2050_ssp126.csv\n",
      "Saved distance_matrices/embedding_mahalanobis_2041-2050_ssp126.csv\n",
      "Saved distance_matrices/embedding_euclidean_2041-2050_ssp126.csv\n",
      "Saved distance_matrices/embedding_mahalanobis_2041-2050_ssp126.csv\n",
      "Saved distance_matrices/embedding_euclidean_2041-2050_ssp370.csv\n",
      "Saved distance_matrices/embedding_mahalanobis_2041-2050_ssp370.csv\n",
      "Saved distance_matrices/embedding_euclidean_2041-2050_ssp370.csv\n",
      "Saved distance_matrices/embedding_mahalanobis_2041-2050_ssp370.csv\n",
      "Saved distance_matrices/embedding_euclidean_2041-2050_ssp585.csv\n",
      "Saved distance_matrices/embedding_mahalanobis_2041-2050_ssp585.csv\n",
      "Saved distance_matrices/embedding_euclidean_2041-2050_ssp585.csv\n",
      "Saved distance_matrices/embedding_mahalanobis_2041-2050_ssp585.csv\n"
     ]
    }
   ],
   "source": [
    "# Save encoder distance matrices to CSV files\n",
    "for key, matrix in encoder_distance_matrices.items():\n",
    "    filename = f'distance_matrices/embedding_{key}.csv'\n",
    "    matrix_to_csv(matrix, filename)\n",
    "    print(f\"Saved {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
